## agenda

- Docker的历史与发展现状
- Docker的技术原理介绍
- Docker的基本概念和术语
- Docker学习的必备基础技能

现在和未来非常重要的技术
主题:why docker 

## PasS(Platform as a Service) 
### 什么是PaaS
首先做这么一个平台，使用该平台的开发者会把很多app放上去，而这些app是使用平台的服务组成(调用平台服务开发的app)，而客户或用户则只需要直接挑选自己所需要的app即可。

PasS在不同人眼里看待是不同的，比如Ms Azure服务，哪些是可以看做是服务
- MarketPlace应用市场(用户找app的所在[app portal])  DataMarket  展现应用本身applications
- Pass平台的运行环境  
框架类的东西是一些基础服务，缓存，nosql，
鉴权  app鉴权 用户认证 ca用户组织机构【通常是给企业内部使用的系统PasS】
集成  服务之间的相互调用，服务总线
存储  一般把数据库提取出来作为服务(每个应用绑定一个数据库实例，但是它不知道它在哪) 
运维
基础设施IaaS

### PaaS平台的范围和内容
1. 确定产品定位和需求，确定首次迭代的范围
2. 制作界面原型
3. 技术选型，然后根据技术选型为每个开发者搭建开发环境和技术栈，例如Java环境、Python环境、Ruby环境、数据库、中间件等等。
4. 构建基础框架和服务，包括日志、存储、消息、缓存、搜索、数据源、负载均衡、集群扩展等等。  
5. 模拟用户容量，构建测试环境。
6. 开始编写真正的业务代码，实现产品功能
7. 迭代开发/测试,生生不息周而复始，直到头发掉光为止......
其中3，4，5属于PasS平台范畴(poc，技术选型之后然后做一个可验证的demo，并可以模拟一定用户容量做性能测试，这过程中较繁琐的是搭建基础开发环境和技术栈)
其中测试环境可能比开发环境要复杂的多...
3,4,5几乎没有写一行代码，却浪费了很多人力做这个环境，包括每个开发者做这个基础环境，而测试在大项目中也是非常多，用户验收测试、功能测试、性能测试、厂商的联调测试
我们发现会有大量的时间花费在这上面搭建各种环境，而且很难保证环境的一致性，而PasS正是为了解决这个问题。

数据库 给你个url就可以使用，至于数据库的主从备份和维护都不需要管。里面需要缓存服务，PasS平台就可以给你装个memcached，你直接用它就行。然后你就写app放在上面就行，PasS给你打包部署好发布上去直接运行。  
需要什么环境，服务，PasS来提供，你只需要将app写好，通过PaaS打包部署发布即可。 (很像aws EMR服务，基础设施服务EC2动态申请，选择Spark环境，指定版本，准备好你的Spark程序，启动脚本，Spark的计算就在EC2实例上运行运算)

## 老一代的PaaS平台的局限性和困境
- 主要提供应用的部署和托管
- 针对应用开发者
- 仅支持特定的IaaS基础技术
- 支持单种语言和开发框架
- 支持特定的服务，比如自定义的数据存储APIs
- 没有很好的解决常用中间件的部署问题(还是由人工手工部署..)
- 难以解决应用和资源的隔离问题 (用一个tomcat部署多个app无法有效的解决资源隔离问题，或者多个jboss部署多个app，又带来部署代价和运维代价的问题)

只能说是比项目稍微成熟，但是无法作为成熟的产品。  

docker难点和热点: 网络方面 docker的单点做得较好，但是跨节点并不是那么好，但并不是docker本身的问题，而是虚拟化技术在网络方面一直是难点和热点 (docker公司在收购socketPlane 很好加强docker的网络方面) 

docker存储的弱点 

大家会发现docker非常的容易上手和方便，与公司理念相关，网络却一直是最复杂的点，而docker公司一直回避网络...这也是为什么网络这块一直没怎么推进的


docker和coreos刚开始的分工，docker做容器，coreos做分布式。  
后台docker觉得只做容器没什么前途(钱途)，于是要往coreos方向发展，开始做网络，存储，分布式，架构，coreos怒了，做了一个新的容器标准，google背后支持coreos，不过最终握手言和

## docker技术原理介绍
docker核心技术
三大核心 lxc  cgrous  aufs 
辅助的
service discovery 
btrfs
jails(另外linux系统的 类似linux lxc)

云计算环境中，linux其实是唯一的竞争者。 

cgroups

**借助于namespace的隔离机制和cgroup的限额机制**，Lxc提供了一套统一的api和工具来建立和管理container。 lxc目的在于提供共享kernal的os级别虚拟化方法，在执行时不用重复加载kernal，且container的kernel与host共享，因此可以大大加快container的启动过程，并显著减少内存消耗，容器在提供隔离的同时，还通过共享这些资源节省开销，这意味着容器比真正的虚拟化的开销要小得多。在实际测试中，基于lxc的虚拟化方法的io和cpu性能几乎接近baremetal的性能。  

lxc虽然隔离非常强大，但是如果内核停止，那么所有的容器就会停止，所以并不是那么强壮(虚机基本不会这么脆弱)


AUFS
层状的文件系统。和ps的层概念非常相似。原有层不变，是共享的，结果是累积叠加的最终结果。当一个进程需要修改一个文件时，AuFS创建给文件的副本。AuFS可以把多层合并成文件系统的单层表示。这个过程被称为写入复制(copy on write)。

底下一层是标准的，这原有层能被很多的文件设施所使用，把不同的差距(插件)放在第二层里面，第二层里面的在放到第三层里面,一层层网上叠加...这样就可以最大化的复用下面的层的目录和数据。这种虚拟化的文件系统直接挂载。
最早支持该技术的ubuntu，所以docker是在ubuntu系统基础发展起来的。后来redhat看到该技术很好，也做了移植支持配合docker。

AuFS允许把某些镜像作为容器的基础。例如，我们可以拥有一个可以作为很多不同容器的基础的centos系统镜像。多亏AuFS，只要一个CentOS镜像的副本就够了，这样既节省了存储和内存，也保证更快速的容器部署。  


使用docker的另一个好处是Docker的版本容器镜像能力。每个新版本是一个与之前版本的简单差异改动，有效的保持镜像文件最小化。但，这也意味着你总是要有一个记录该容器从一个版本到另一个版本改动的审计跟踪。

Docker原理之App打包
writable Container  最上层是可写的
jenkins Image [referce Base Image]
gitlab Image  [referce Base Image]
ubuntu [Base Image]
lxc aufs/btrfs  Kernel

共享使得docker非常精简和高效

### Docker全生命周期开发模式
将开发延伸到部署升级
build ship run 

docker hub 类似github repository/svn repository等 但不存储代码而是存储image
docker本身和dockerhub 关联，如果发现本地没有要启动的镜像，其就会主动去docker hub拉取。  


官方registry(docker hub)

web ui/api server ==> docker hub
存储服务 ==> docker registry 集群




kubernetes 
pod 最小的任务调度单元
replication controller (rc) 用于保持pod任务数量不变的功能性单元。
每个rc对应一定数量的pod，而pod数量因为故障减少或故障恢复变多，这样的情况发生会自动地调整pod的数量。本身来说是功能的概念。可以称之为冗余控制

service也是功能性的抽象概念，本身代表着对外暴露服务的端口，以及在该端口上面，进行端口映射，和流量负载均衡的单元模块。每一个这样的单元模块就会声明这样的一个servcie元素。


deployment：抽象概念，代表服务的部署操作，一般和 service一起使用介绍。

两种特别类型的部署
DaemonSet:通过daemonSet部署服务，会在集群的每一个节点都运行一个拷贝，通常是做一些日常的信息收集和比较底层的基础服务比较相关的功能
job      :部署的是一类运行完成就会结束的批量任务的服务。
namespace:每一个资源都是属于特定的namespace，该ns就限定了资源所有人能够访问的范围，并且使得每个ns都觉得像是在占用整个kubernetes资源池。不同的资源池的不同资源的namespace是可以重复的。命名上的隔离，在docker的资源隔离概念上又增加了租户隔离的概念(不同用户登录系统看到不同桌面，得到不同的配置)

kubernetes下做集群管理和容器部署大概是怎样的过程?
假设我们有需要部署和调度的任务
首先我们需要确定它属于哪个组织单元，也就是确定其namespace
然后确定该任务的运行方式，如果长期的后台运行，deployment
批量的单次集群任务或定时集群任务的话，job
如果是一个普适性的任务，在每个地方都需要长期运行的，daemontSet
此外如果服务需要对外提供访问的话，我们还需要service
最后将刚刚提高的任务补充全其所需要的对象参数，分别写成一个或者几个的对象描述文件，在kubernetes中称为资源描述文件，将资源描述文件传递给kubernetes，然后通过k8s的命令行工具或者api接口，然后等上两分钟，k8s会自动的把这些任务服务按照我们所丰富的方式所部署好和安排好。这样就可以欢乐的使用我们的服务了。

构建k8s集群
aws-ssh-to s...n
每个环境中都要提前安装好docker环境

主从结构的部署方式
根据具体的职责进行详细的划分

1. 集群基础设施
 包括k8s所依赖元数据的存储服务和集群的网络规划和管理的服务
主要是
etcd
flannel/calico

2. k8s服务
master
node 
k8s服务部署节点看似多，但只不过是多起了几个应用程序而已
主要目的是各个功能从模块上解耦，以后可以被其他重新实现的模块所替代

3. 自带插件服务（非必须）
有时会自动安装，或额外的自己手动部署。看需求

## k8s的安装
官网提供很多各个平台自动化的安装脚本非常方便！
但是手工部署会对其认识更清晰些。  

手工部署与具体的平台环境无关，也就是公、私有云，物理，虚拟主机都可以部署。  
对机器的性能要求不是很高。

### 安装包和依赖包
最主要的是etcd和flannel或calico以及k8s本身。  





































































